{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network based on backward automatic differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kinds of irises:\n",
    "\n",
    "    * setosa     = [1.0  0.0  0.0]\n",
    "    * versicolor = [0.0  1.0  0.0]\n",
    "    * virginica  = [0.0  0.0  1.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"data_preparing.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Data preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_dataset = prepare_iris();\n",
    "train_set, test_set = split_dataset(iris_dataset, 0.8);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "include(\"automatic_differentiation.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Design architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "net (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function dense(w, b, x, activation) return activation.(w * x .+ b) end\n",
    "function dense(w, x, activation) return activation.(w * x) end\n",
    "function dense(w, x) return w * x end\n",
    "\n",
    "function mean_squared_loss(y, ŷ)\n",
    "    return Constant(1.0/3.0) .* sum.((y .- ŷ) .^ Constant(2))\n",
    "end\n",
    "\n",
    "function net(x, Wh, Wo, y)\n",
    "    x̂ = dense(Wh, x, σ)\n",
    "    x̂.name = \"x̂\"\n",
    "    ŷ = dense(Wo, x̂, softmax)\n",
    "    ŷ.name = \"ŷ\"\n",
    "    E = mean_squared_loss(y, ŷ)\n",
    "    E.name = \"total_loss\"\n",
    "    return topological_sort(E)\n",
    "end    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dnet (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function dnet(E)\n",
    "    forward!(E)\n",
    "    backward!(E)\n",
    "    tuple(E[4].gradient, E[3].gradient, E[14].output)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "optimize! (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function optimize!(Wh::Variable, Wo::Variable, dWh::Matrix, dWo::Matrix, α::Float64)\n",
    "    Wh.output -= α * dWh\n",
    "    Wo.output -= α * dWo\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "learn_BGD (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function learn_BGD(x::Variable, Wh::Variable, Wo::Variable, y::Variable, epochs::Int64, α::Float64)\n",
    "    E = net(x, Wh, Wo, y)\n",
    "    total_losses = Vector()\n",
    "    for i=1:epochs\n",
    "        input_data, expected_values = adjust_dataset(train_set)\n",
    "        dWh = zeros(length(Wh.output[:,1]), length(Wh.output[1,:]))\n",
    "        dWo = zeros(length(Wo.output[:,1]), length(Wo.output[1,:]))\n",
    "        epoch_loss = .0\n",
    "        for j=1:length(input_data[:,1])\n",
    "            x.output = input_data[j,:]\n",
    "            y.output = expected_values[j,:]\n",
    "            tmp_dWh, tmp_dWo, tmp_loss = dnet(E)\n",
    "            dWh += tmp_dWh\n",
    "            dWo += tmp_dWo\n",
    "            epoch_loss += tmp_loss\n",
    "        end\n",
    "        dWh ./= length(input_data[:,1])\n",
    "        dWo ./= length(input_data[:,1])\n",
    "        append!(total_losses, epoch_loss/length(input_data[:,1]))\n",
    "        optimize!(Wh, Wo, dWh, dWo, α)\n",
    "    end\n",
    "    tuple(E, total_losses)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mini-batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "learn_MBGD (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function learn_MBGD(x::Variable, Wh::Variable, Wo::Variable, y::Variable, epochs::Int64, batch_size::Int64, α::Float64)\n",
    "    E = net(x, Wh, Wo, y)\n",
    "    total_losses = Vector()\n",
    "    last_batch = length(train_set[:,1]) % batch_size\n",
    "    for i=1:epochs\n",
    "        input_data, expected_values = adjust_dataset(train_set)\n",
    "        dWh = zeros(length(Wh.output[:,1]), length(Wh.output[1,:]))\n",
    "        dWo = zeros(length(Wo.output[:,1]), length(Wo.output[1,:]))\n",
    "        batch_loss = .0\n",
    "        for j=1:length(input_data[:,1])\n",
    "            x.output = input_data[j,:]\n",
    "            y.output = expected_values[j,:]\n",
    "            tmp_dWh, tmp_dWo, tmp_loss = dnet(E)\n",
    "            dWh += tmp_dWh\n",
    "            dWo += tmp_dWo\n",
    "            batch_loss += tmp_loss\n",
    "            if j % batch_size == 0\n",
    "                append!(total_losses, batch_loss/batch_size)\n",
    "                batch_loss = .0\n",
    "                dWh ./= batch_size\n",
    "                dWo ./= batch_size\n",
    "                optimize!(Wh, Wo, dWh, dWo, α)\n",
    "                dWh = zeros(length(Wh.output[:,1]), length(Wh.output[1,:]))\n",
    "                dWo = zeros(length(Wo.output[:,1]), length(Wo.output[1,:]))\n",
    "            end\n",
    "        end\n",
    "        if length(input_data[:,1]) % batch_size != 0\n",
    "            append!(total_losses, batch_loss/last_batch)\n",
    "            dWh ./= last_batch\n",
    "            dWo ./= last_batch\n",
    "        end\n",
    "        optimize!(Wh, Wo, dWh, dWo, α)\n",
    "    end\n",
    "    tuple(E, total_losses)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "learn_SGD (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function learn_SGD(x::Variable, Wh::Variable, Wo::Variable, y::Variable, epochs::Int64, α::Float64)\n",
    "    E = net(x, Wh, Wo, y)\n",
    "    total_losses = Vector()\n",
    "    for i=1:epochs\n",
    "        input_data, expected_values = adjust_dataset(train_set)\n",
    "        epoch_loss = .0\n",
    "        for j=1:length(input_data[:,1])\n",
    "            x.output = input_data[j,:]\n",
    "            y.output = expected_values[j,:]\n",
    "            dWh, dWo, tmp_loss = dnet(E)\n",
    "            epoch_loss += tmp_loss\n",
    "            optimize!(Wh, Wo, dWh, dWo, α)\n",
    "        end\n",
    "        append!(total_losses, epoch_loss/length(input_data[:,1]))\n",
    "    end\n",
    "    tuple(E, total_losses)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict_result (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function predict_result(E, input)\n",
    "    E[5].output = input\n",
    "    forward!(E)\n",
    "    E[9].output\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count_accuracy (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function count_accuracy(E, input_data, expected_values)\n",
    "    if length(input_data[:,1]) != length(expected_values[:,1]) || length(input_data[:,1]) < 1\n",
    "        return \"Incorrect size of dataset!\"\n",
    "    end\n",
    "    predicts = zeros(0,3)\n",
    "    for i=1:length(input_data[:,1])\n",
    "        p = predict_result(E, input_data[i,:])\n",
    "        predicts = vcat(predicts, p')\n",
    "    end\n",
    "    positive = 0\n",
    "    negative = 0\n",
    "    for i=1:length(predicts[:,1])\n",
    "        if argmax(predicts[i,:]) == argmax(expected_values[i,:])\n",
    "            positive += 1\n",
    "        else\n",
    "            negative += 1\n",
    "        end\n",
    "    end\n",
    "    100.0 * positive / (positive + negative)\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
